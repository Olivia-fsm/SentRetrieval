Techniques from Natural-Language-Processing offer the opportunities to design new dialog-based forms of human-computer interaction as well as to analyze the argumentation quality of texts. [CLS] [SEP] This can be leveraged to provide students with adaptive tutoring when doing a persuasive writing exercise. [CLS] [SEP] To test if individual tutoring for students’ argumentation will help them to write more convincing texts, we developed ArgueTutor, a conversational agent that tutors students with adaptive argumentation feedback in their learning journey. [CLS] [SEP] We compared ArgueTutor with 55 students to a traditional writing tool. [CLS] [SEP] We found students using ArgueTutor wrote more convincing texts with a better quality of argumentation compared to the ones using the alternative approach. [CLS] [SEP] The measured level of enjoyment and ease of use provides promising results to use our tool in traditional learning settings. [CLS] [SEP] Our results indicate that dialog-based learning applications combined with NLP text feedback have a beneficial use to foster better writing skills of students.
ACM Reference Format: Thiemo Wambsganss, Tobias Kueng, Matthias Soellner, and Jan Marco Leimeister. [CLS] [SEP] 2021. [CLS] [SEP] ArgueTutor: An Adaptive Dialog-Based Learning System for Argumentation Skills. [CLS] [SEP] In CHI Conference on Human Factors in Computing Systems (CHI '21), May 8–13, 2021, Yokohama, Japan. [CLS] [SEP] ACM, New York, NY, USA 13 Pages. [CLS] [SEP] https://doi.org/10.1145/3411764.3445781
Today, information can constantly be accessed, so people need to develop skills that go beyond the replication of factual knowledge. [CLS] [SEP] Hence, the requirements of job profiles are shifting towards more interdisciplinary, ambiguous and creative tasks . [CLS] [SEP] The current Covid19-pandemic crisis has strengthened this effect even further, since due to governmental lockdowns distance-learning scenarios have become a reality for many educators.
One possible solution to imitate meaningful, individual instructor–learner interactions are pedagogical conversational agents (PCAs) . [CLS] [SEP] However, current literature sparsely investigates an approach with principles and proof on how to design an adaptive dialog-based learning system that guides and helps students to learn how to argue when writing a persuasive text.
Given this potential for leveraging a conversational learning tool in combination with argumentation mining, we designed and built ArgueTutor (short for Argumentation Tutor), an adaptive dialog-based tutoring system that provides students with adaptive and instant feedback, theoretical input and step-by-step guidance during their writing process. [CLS] [SEP] We followed two different development approaches: 1) a rigorous theory-motivated approach, where we systematically searched literature in the field of educational technology and HCI following to carefully derive requirements and principles for a design of ArgueTutor, and 2), a user-centered design approach, where we conducted twelve semi-structured interviews with students to derive user stories. [CLS] [SEP] Based on these user needs, we built low-fidelity prototypes of ArgueTutor to test different design hypotheses with potential users to learn about the interaction flow of a dialog-based learning tool for argumentation. [CLS] [SEP] With these two approaches, we present our final version of ArgueTutor.
To design an adaptive dialog-based learning tool, we a) trained the intents of a conversational tutor based on rigorously scripted teacher-student conversations and b) developed an argumentation mining model to assess the argumentation quality of student texts. [CLS] [SEP] To do so, we leveraged the argumentation annotated business-model peer review corpus of to classify the argumentation quality of student texts. [CLS] [SEP] In combination with the trained chat intents, this model now serves as the underlying adaptive tutoring algorithm of ArgueTutor.
To determine the impact of ArgueTutor on students’ argumentation skills and perception during the learning process, we evaluated our learning tool in comparison with a discussion scripting approach that provided general argumentation feedback based on argumentation theory . [CLS] [SEP] We found that both constructs provide promising results for the usage of ArgueTutor as a standard learning tool in lectures. [CLS] [SEP] The results suggest that ArgueTutor helps students to write more structured texts and motivates them to write more persuasive texts in peer learning settings, such as peer feedback scenarios.
This work has three main contributions. [CLS] [SEP] First, with ArgueTutor we introduce the first intelligent dialog-based tutoring system for argumentation skills. [CLS] [SEP] Second, we show its effectiveness through rigorously comparing ArgueTutor with a traditional writing support scenario for argumentation skills. [CLS] [SEP] The results provide insights into the benefits of leveraging NLP and ML for designing intelligent dialog-based tutoring systems to foster argumentative writing in a student's learning journey. [CLS] [SEP] Our results demonstrate an exemplary scenario of supporting metacognition skills in a scalable and individual way in possible large- or distance-scale scenarios. [CLS] [SEP] Finally, we provide design knowledge for other researchers and educators to design and compare similar adaptive learning tools to foster the metacognition skill learning of students as a step to contribute to the OECD Learning framework 2030 towards a metacognition-skill-based education.
Our work was inspired by previous studies on technology-based learning systems for argumentation, by studies about argumentation mining algorithms and by PCAs and the ICAP framework , which serves as an underlying conceptual model for our main hypothesis.
Argumentation skills build the basis for our daily communication and thinking. [CLS] [SEP] In general, argumentation aims at increasing or decreasing the acceptability of a controversial standpoint .
Hence, researchers, especially from the fields of educational technology and HCI, have analyzed how technology-based learning systems can address this gap and enhance students’ learning of argumentation. [CLS] [SEP] The application of information technology in education bears several advantages, that is, consistency, scalability, perceived fairness, widespread use, better availability compared to human teachers, etc., and thus IT-based argumentation systems can help to relieve some of the burden on teachers to teach argumentation by supporting learners in creating, editing, interpreting or reviewing arguments , three different technology-based argumentation learning systems in the field of CSCL and ITS can be distinguished:
Our learning tool combines recent advances in NLP, ML and AM to evaluate new forms of human–computer interaction, such as adaptive PCAs, to intelligently tutor students in their individual argumentation learning process, e.g., with adaptive and instant feedback or theoretical input. [CLS] [SEP] Therefore, we build on adaptive support approaches to assess the potential of adaptive argumentation skill learning .
The foundation of argumentation mining (AM) is argumentation theory. [CLS] [SEP] Argumentation theory is about analyzing the structure and the connection between arguments. [CLS] [SEP] One of the most prominent argumentation models is the Toulmin model . [CLS] [SEP] During the identification of these argumentation structures, three subtasks can be distinguished:
Researchers have developed increasing interest in intelligent writing assistance . [CLS] [SEP] In our approach we focus on the first two subtasks to assess the argumentation level of a student to provide individual tutoring.
Conversational Agents (CA) are software programs that are designed to communicate with users through natural language interaction interfaces .
A benefit of using the technology of PCAs compared to traditional technology-enhanced argumentation learning systems is the increasing engagement of the students due to the dialog-based interaction of the learners with the PCA. [CLS] [SEP] According to the ICAP Framework (i.e., Interactive, Constructive, Active and Passive Framework) by , but it has not been investigated for argumentation skills. [CLS] [SEP] Therefore, we believe that a theory-motivated and user-centered design of an adaptive PCA combined with intelligent algorithms to provide learning tutoring for argumentation skills by individually assisting students in writing persuasive texts would interactively foster learning according to the ICAP Framework.
In this section, we will explain how we designed and built the two main components of ArgueTutor: the dialog-based user interaction and the adaptive feedback algorithm in the back end. [CLS] [SEP] The basic user interaction concept of ArgueTutor is illustrated in Figure 2. [CLS] [SEP] T user does a persuasive writing task and receives adaptive tutoring and feedback on the argumentation.
Deriving theory requirements. [CLS] [SEP] To build a theory-motivated and user-centered learning tool, we followed two different approaches: a rigorous theory-driven approach and an agile user-centered approach following the build-measure-learn paradigm to conduct a systematic literature review with the aim of deriving a set of theory requirements for the design of a dialog-based argumentation learning system. [CLS] [SEP] We initially focused our research on studies that demonstrate the successful implementation of learning tools for argumentation skills and PCAs. [CLS] [SEP] The design of a conversational learning tool for argumentation skills is a complex project that is studied by psychologists, pedagogues and computer scientists with different methods. [CLS] [SEP] Therefore, we firstly concentrated on two main literature streams for deriving requirements: educational technology and HCI. [CLS] [SEP] We only included studies that dealt with or contribute to a kind of learning tool in the field of argumentation learning or dialog-based learning systems, such as an established pedagogical theory. [CLS] [SEP] On this basis, we selected 85 papers for more intensive analysis. [CLS] [SEP] We have summarized similar topics of these contributions as literature issues and formed five clusters from them, which served as theory requirements for dialog-based learning tools for metacognition skills.
Deriving user requirements. [CLS] [SEP] Besides the rigorous theory-driven approach, we followed a continued user-centered design approach at the same time. [CLS] [SEP] As a start, we conducted twelve user interviews with students to receive an initial understanding of the needs and requirements of learners for a dialog-based learning tool for argumentation. [CLS] [SEP] Therefore, we followed the expert interview method of . [CLS] [SEP] Building on the user stories, we designed low-fidelity prototypes of ArgueTutor to test different design hypotheses with end users to learn more about the conversational flows and the human-computer interaction of an adaptive tutoring system for argumentation skills. [CLS] [SEP] We started the testing with seventeen low-fidelity paper prototypes and later two digital mock-ups of ArgueTutor. [CLS] [SEP] For example, we hypothesized that students aim to learn with a humanized conversational learning tool. [CLS] [SEP] We tested this hypothesis with three different paper prototypes. [CLS] [SEP] Prototype one was embedded in a rather functional design without incorporating humanized design elements such as a profile picture. [CLS] [SEP] Prototypes two and three were designed with a higher level of anthropomorphic elements (e.g., a profile picture and emoticons in a more colloquial conversation). [CLS] [SEP] The tutoring and feedback algorithm was simulated by a human. [CLS] [SEP] The hypothesis was validated with 16 users. [CLS] [SEP] However, we learned that the majority of students rather like a functional design with a low level of anthropomorphic elements. [CLS] [SEP] Therefore, the final version of ArgueTutor contributes to that with a rather functional design.
Deriving design principles. [CLS] [SEP] In total, we conducted three cycles with a total of 77 different users (16 in cycle one, 16 in cycle two and 45 in cycle three). [CLS] [SEP] These users were different to the ones recruited for the semi-structured interviews but also students from our university with a similar age and gender distribution. [CLS] [SEP] Based on those two approaches, we finally came up with five design principles on how to build an adaptive dialog-based learning system for argumentation skills illustrated in Table 1. [CLS] [SEP] The design principles were followed in the instantiation of our current version of ArgueTutor.
User Interaction of ArgueTutor. [CLS] [SEP] Following the design principles, ArgueTutor is built as a responsive web-based application that can be used on all kinds of devices. [CLS] [SEP] A screenshot of ArgueTutor and its core functionalities (e.g., F1 - F7) can be seen in Figure 1 1. [CLS] [SEP] ArgueTutor consists of two modes: an adaptive learning mode and a casual chat mode. [CLS] [SEP] The dialog flow of ArgueTutor with the two interaction modes can be seen in Figure 3. [CLS] [SEP] The basis dialog flow of the adaptive learning mode of ArgueTutor was designed according to the didactical learning phases of ”Motivation, Difficulty, Solution, and Practice” according to .
ArgueTutor guides students through a writing exercise with the aim to imitate a human educator (F1, F2 and F3). [CLS] [SEP] The PCA proactively explains a writing task (e.g., students have to write persuasive peer feedback to a fellow student) (F3) and provides hints and explanations when the user asks for help such as argumentation theory input and provide a small explanation for the individual score (e.g., if less than 40, recommendations to improve the readability). [CLS] [SEP] The interactions between the user and ArgueTutor are mixed between both typing and button selections. [CLS] [SEP] While writing a persuasive text for an exercise is typing based, selecting from multiple choices, asking for a task explanation or theory input are button based. [CLS] [SEP] Predefined answer buttons help the user to receive an overview of the learning process and ensure both flexibility and efficiency regarding user interactions with ArgueTutor (F8). [CLS] [SEP] Moreover, ArgueTutor incorporates a user-initiated and rule-based casual chat mode. [CLS] [SEP] Students can ask ArgueTutor to tell jokes, fun facts or talk about the weather to take a break from the primary learning activity (see Figure 1, F7) and thus change from the argumentation learning mode to the casual chat mode at any time they want. [CLS] [SEP] To imitate the students having a personal learning session with a human educator, we incorporated several more functions to incorporate real-world conversational elements into ArgueTutor's design. [CLS] [SEP] For example, we provided a wide variety of different responses to common conversation states such as “how are you?” as well as positive reinforcement feedback that is typical of a study partner. [CLS] [SEP] The result of the dialog path of ArgueTutor from a user perspective is depicted in Figure 3.
The learning mode is based on a rule-based chat system combined with a supervised argumentation mining model to assess the argumentation level of students. [CLS] [SEP] The adaptivity of the argumentation feedback is implemented by training a model based on a corpus of persuasive student-written texts. [CLS] [SEP] The argumentation theory guidance, the task explanation and other tutoring functions are implemented through rule-based trained chat intents based on a word-to-vec model following the architecture of rasa nlu and rasa core .
All in all, we only included simple design elements in the design of ArgueTutor, since we received the user feedback to offer a more formal and functional tutoring experiences that does not distract students. [CLS] [SEP] However, we believe these design principles might change depending on culture and context and can thus be easily adapted, e.g., by embedding ArgueTutor in a human persona with a name, face, picture and the use of emojis.
To design an adaptive dialog-based learning tool with individual and adaptive guidance, we trained and tuned a transfer learning model that fulfils the users’ requirements to receive adaptive and instant tutoring and feedback on their texts.
A major prerequisite for developing supervised ML models based on NLP that are able to identify argumentative texts and argument components in written texts is the availability of annotated corpora fulfilled all these requirements. [CLS] [SEP] The corpus consists of 1000 business model peer feedback essays written by students extracted from a large-scale lecture scenario. [CLS] [SEP] The texts are annotated for their argumentative components (claim, premise) as well as for the relations of the components.
Guided by recent literature about AM . [CLS] [SEP] We used the BERT model from deepset2, since it is available for German and provides a deep pretrained model that was unsupervised while training on domain-agnostic German corpora (e.g., the German Wikipedia). [CLS] [SEP] The novelty of this architecture is the ability to capture semantic information from pretrained texts, which can then be used for other downstream tasks without the need for retraining, e.g., for identifying argumentative components. [CLS] [SEP] For applying the model, the corpus texts were split into word tokens to fulfill the preparation requirements for BERT. [CLS] [SEP] The special preprocessing for BERT was conducted by utilizing the tokenizer and processor provided by deepset and by utilizing spacy3. [CLS] [SEP] The goal of our model is to provide accurate predictions to identify and classify argument components that can be used for accessing the skill level of students and thus provide adaptive guidance and feedback on how to improve their argumentation.
We split the data into 70 % training, 20 % validation and 10 % test data our LSTM only reached an unsatisfying f1 score of 57 % (16 % lower then the 73 % of our BERT model).
To evaluate ArgueTutor, we compared it with a nonadaptive discussion scripting application, since this approach was empirically proven to foster the formal quality of the argumentation of students .
In this section, we describe the experimental setup for our study. [CLS] [SEP] Our goal was to evaluate our hypothesis that adaptive tutoring on student's argumentation will help them to write more convincing texts. [CLS] [SEP] To evaluate our hypothesis, we designed an experiment in which participants were asked to write a peer review based on a given essay. [CLS] [SEP] Participants were randomly assigned to a treatment and a control group. [CLS] [SEP] The treatment group used ArgueTutor to do the writing exercise, while participants in the control group used the alternative learning tool. [CLS] [SEP] We recruited 55 students from our university to take part in our experiment. [CLS] [SEP] The experiment was conducted as a web experiment facilitated by the behavioral lab of our university. [CLS] [SEP] After randomization, we counted 31 valid results in the treatment and 24 in the control group. [CLS] [SEP] Participants of the treatment group had an average age of 22.75 (SD= 1.96), 17 were male, 14 female. [CLS] [SEP] In the control group, participants’ average age was 23.52 (SD= 2.81), 11 were male, 13 female. [CLS] [SEP] All participants were compensated with an equivalent of about 12 USD for a 25- to 30-minute experiment.
The experiment consisted of three main parts: 1) pretest, 2) writing exercise and 3) posttest. [CLS] [SEP] The pre- and post-phases were consistent for all participants. [CLS] [SEP] In the writing phase, the treatment group used ArgueTutor to conduct a persuasive writing exercise, whereas participants of the control group conducted the same exercise using the alternative tool.
1) Pretest: The experiment started with a pre-survey of 14 questions. [CLS] [SEP] Here, we tested three different constructs to assess whether the randomization was successful. [CLS] [SEP] First, we asked four items to test the personal innovativeness in the domain of information technology of the participants following .
2) Writing exercise: In the writing part of the experiments, we asked the participants to conduct a persuasive writing tasks, simulating a typical student essay homework. [CLS] [SEP] We asked the students to write a review about the discussion from the pre-survey. [CLS] [SEP] Therefore, students were asked to assess the argumentation of both parties (pro and contra) concerning the weaknesses and strengths of their argumentation. [CLS] [SEP] The participants were told to spend at least 15 minutes on writing this review. [CLS] [SEP] A countdown indicated them the remaining time. [CLS] [SEP] They were only able to continue the experiment after the countdown was finished. [CLS] [SEP] The treatment group was using ArgueTutor to write the review, the control group was using the reference tool. [CLS] [SEP] We did not provide any introduction to any of the tools. [CLS] [SEP] The students using ArgueTutor were adaptively tutored through the writing exercise, e.g., through theory input, individual recommendations and adaptive argumentation feedback based on our feedback algorithm. [CLS] [SEP] Participants using the reference tool retrieved help based on argumentation theory input and general argumentation recommendations during the writing process following .
3) Posttest: In the post-survey, we measured the perceived level of enjoyment of the students, since enjoyment during a learning process has a major influence on the adoption of IT tools and captured the demographics. [CLS] [SEP] In total, we asked 13 questions. [CLS] [SEP] Finally, we asked three qualitative questions: ”What did you particularly like about the use of the argumentation tool?”, ”What else could be improved?” and ”Do you have any other ideas?”
Besides measuring the ease of use and the level of enjoyment, our main objective was to measure the quality of the written texts from both groups to evaluate our main hypothesis. [CLS] [SEP] Therefore, we measured two main variables: 1) the formal quality of argumentation and 2) the perceived quality of argumentation.
1) Formal quality of argumentation: The written peer reviews were analyzed for the formal quality of argumentation. [CLS] [SEP] We applied the annotation scheme for argumentative knowledge construction described by , only supported, limited and supported and limited claims were counted as argumentation.
2) Perceived quality of argumentation: The perceived quality of argumentation was annotated by the same three annotators. [CLS] [SEP] The objective was to subjectively judge how persuasive the given argumentation is on a Likert scale from 1 to 5 points (1: not very persuasive, 5: very persuasive). [CLS] [SEP] We took the mean of all three annotators as a final variable for the formal and the perceived quality of argumentation of the texts.
To evaluate our hypothesis that adaptive tutoring on students’ argumentation will help them to write more convincing texts, our objective was to answer two research questions (RQ):
RQ1: How effective is ArgueTutor at helping users to write more persuasive texts compared to the traditional approach?
RQ2: Do students perceive the interaction with ArgueTutor as easy and enjoyable to use during their writing process, and would they continue to use it in the future?
To evaluate our first research question, we compare the formal quality of argumentation and perceived quality of argumentation between the written text of the treatment and the control group. [CLS] [SEP] Therefore, we applied a Welch Two Sample t test to evaluate whether the means of the constructs are significantly different between the groups.
The second research question will be answered by comparing the constructs of perceived ease of use and level of enjoyment for participants using ArgueTutor compared to participants using the alternative tool. [CLS] [SEP] We performed a Welch Two Sample t test to assess whether differences between both groups are statistically significant. [CLS] [SEP] Moreover, we compared the results of ArgueTutor to the midpoints scale to validate a general positive technology acceptance as done in . [CLS] [SEP] To ensure that the randomization resulted in randomized groups and to control for potential effects of interfering variables with our small sample size, we compared the differences in the means of the three constructs included in the pretest. [CLS] [SEP] For all three constructs, including personal innovativeness, feedback-seeking of individuals and passive argumentative competency, we received p values larger than 0.05 between the treatment and the control groups (for personal innovativeness p= 0.1436, for feedback-seeking of individuals p= 0.7537 and for passive argumentative competency p= 0.8495). [CLS] [SEP] This demonstrated that no significant difference in the mean values for these three constructs exists between the groups.
The mean number of arguments in the texts from participants using ArgueTutor for the writing exercise was 3.56 (SD= 1.81). [CLS] [SEP] For the texts from participants using the alternative static tool, we counted a mean of 2.64 arguments (SD= 1.21) (see Figure 2). [CLS] [SEP] A double-sided t test confirmed that the treatment group wrote texts with a statistically significantly higher quality of formal argumentation: t value= 2.1738 and p value= 0.03459 (p<0.05). [CLS] [SEP] For the perceived quality of argumentation, we found that on a Likert scale from 1 to 5 points (1: not very persuasive, 5: very persuasive) texts from the treatment group achieved an average value of 3.48 (SD= 0.83). [CLS] [SEP] Participants using the alternative application wrote texts with a mean value of the perceived quality of argumentation of 2.80 (SD= 1.43). [CLS] [SEP] A double-sided t test showed that the difference was statistically significant: t value= 2.114 and p value= 0.03961 (p<0.05). [CLS] [SEP] This clearly proves our hypothesis that adaptive dialog-based tutoring during students’ argumentative writing process helps them to write more convincing texts. [CLS] [SEP] The results show that students using ArgueTutor wrote texts with a better formal quality of argumentation and with a better perceived quality of argumentation compared to the ones using the static traditional approach.
To evaluate the students’ perception, we calculated the means of the perceived ease of use and the level of enjoyment. [CLS] [SEP] We compared the results of ArgueTutor with the results of the alternative tool. [CLS] [SEP] The perceived ease of use of ArgueTutor was rated with a mean value of 3.73 (SD= 0.64) and the average of perceived level of enjoyment of ArgueTutor was 3.41 (SD= 0.89). [CLS] [SEP] These values are significantly better than the results of the alternative approach. [CLS] [SEP] For perceived ease of use we observed a mean value of 3.45 (SD= 0.69) and for perceived level of enjoyment the value was 3.00 (SD= 0.88) for participants from the control group. [CLS] [SEP] The results show that the participants of our experiment rated the ease of use of ArgueTutor as an adaptive dialog-based tutoring system positively compared to the usage of the alternative application. [CLS] [SEP] The statistical significance was also proven in a double-sided t test for all three constructs (see Table 3). [CLS] [SEP] Moreover, the mean values of ArgueTutor are also very promising when comparing the results to the midpoints. [CLS] [SEP] All results are better than the neutral value of 3, indicating a very positive value for level of enjoyment and perceived ease of use. [CLS] [SEP] A high level of enjoyment and ease of use is especially important for learning tools to ensure students are experiencing joy in the usage of the tool and they find it easy to interact with. [CLS] [SEP] This will foster motivation, engagement and adoption to use the learning application.
We also asked open questions in our survey to receive the participants’ opinions about the tool they used. [CLS] [SEP] The general attitude for ArgueTutor was quite positive. [CLS] [SEP] Participants positively mentioned the fast and adaptive feedback (F4 and F5), the simple conversational interaction flow and the adaptive feedback message with the readability score (F5 and F6) several times. [CLS] [SEP] However, participants also asked if ArgueTutor could provide even more detailed feedback about the argumentation (e.g., through displaying argumentative relations between the components) and provide transparent explanations on how the feedback mechanism works. [CLS] [SEP] We translated the responses from German and clustered the most representative responses in Table 4.
Our research study illustrated that adaptive dialog-based tutoring on students’ argumentation skills during a writing exercise helps them to write more persuasive texts. [CLS] [SEP] The perceived and the formal argumentation quality was significantly higher for students using ArgueTutor compared to the ones using an alternative discussion scripting apprach for the exact same writing exercise. [CLS] [SEP] We believe that the ICAP framework could explain our results. [CLS] [SEP] Accordingly, a dialog-based interactive learning journey increases the engagement of the students compared to an active learning scenario. [CLS] [SEP] Therefore, the user-centered and theory-based design of an adaptive PCA combined with intelligent algorithms interactively fosters learning according to the conceptual model of the ICAP framework . [CLS] [SEP] Also, the perceived ease of use and the level of enjoyment showed positive results for the usage of a learning tool in a real-world scenario. [CLS] [SEP] Especially a high level of enjoyment during the learning process is important for the long-term adaption of such learning tools, since this is proven to foster motivation and engagement in the learning process.
Hence, our work makes several contributions to current research. [CLS] [SEP] To the best of our knowledge, this study is one of the first to present empirical insights into how to design a dialog-based learning tool to foster argumentation skills of students based on adaptive and intelligent tutoring. [CLS] [SEP] It provides a foundation for researchers who also aim to develop learning tools to train metacognition skills to compare their solution with ours (e.g., for empathy skills ). [CLS] [SEP] Educators can now use our design findings and principles to build their own adaptive PCAs to support argumentation learning in their large-scale or distance-learning scenarios.
Based on the qualitative user feedback, we see three main improvements to enhance ArgueTutor. [CLS] [SEP] First, we aim to improve the details of our argumentation text feedback by displaying the argumentative relations between the components through a graph engine. [CLS] [SEP] Therefore, students receive an additional overview of the discourse of their argumentation. [CLS] [SEP] Second, we aim to improve the transparency of our recommendations and explanations by providing a question mark button in the upper right corner of our PCA. [CLS] [SEP] Students can see transparent explanations for the adaptive tutoring at any time they want. [CLS] [SEP] Third, we want to train our PCA on different argumentation mining corpora to extend the contribution of our learning tool to other domains and languages (e.g., English student essays or English law cases).
Our study also faces limitations. [CLS] [SEP] For the aim of this study, we focused our research on students from our university. [CLS] [SEP] Even though it is reasonable to assume that the transferability to other cases is possible without major changes, we cannot prove it with our research design. [CLS] [SEP] Moreover, even if 85% of the participants stated they have used a conversational agent before, novelty effects of students using our PCA for the first time cannot be expelled in our empirical results. [CLS] [SEP] In our experiment we prove the short-term influence of ArgueTutor on a student's argumentation skills. [CLS] [SEP] For future work we suggest to measure the long-term learning effects on students’ skills. [CLS] [SEP] This can be achieved with a longitudinal study in a real-world learning setting, e.g., in tutoring the writing process of peer reviews in business model lectures. [CLS] [SEP] Therefore, particularly for analyzing the long-term effect of using ArgueTutor, we aim to implement the artifact into our existing learning management system (blinded for review) and measure long-term effects on usability and the acceptance of skill learning with a PCA during the complete three month life cycle of a lecture. [CLS] [SEP] We want to investigate the hypothesis that adaptive dialog-based tutoring influences the long-term argumentation skills of students. [CLS] [SEP] At the end of the study, we want to contribute with an evaluated learning tool that can be used in a learning-teaching scenario where students do a certain writing exercise and receive adaptive tutoring during the writing process by an intelligent PCA. [CLS] [SEP] Regarding the implementation of our PCA, we clearly do not want to replace human tutors, since we believe that skilled teachers will always be able to provide better adaptive skill tutoring than a PCA. [CLS] [SEP] However, we hope through our system human tutors can focus more on detailed questions and can devote more time to difficult cases.
In our research project, we designed, built and evaluated ArgueTutor, an adaptive dialog-based learning system that individually tutors students with task explanations, theory input, guidance and adaptive feedback on the argumentation structure of a text by leveraging the recent advances of AM algorithms. [CLS] [SEP] We compared ArgueTutor to a discussion scripting approach in an experiment with 55 participants. [CLS] [SEP] We found that students using ArgueTutor to conduct a writing exercise wrote more convincing texts with a better formal quality of argumentation compared to the traditional approach. [CLS] [SEP] The perceived ease of use and enjoyment offers promising results to use ArgueTutor as a learning tool in different learning scenarios. [CLS] [SEP] All in all, our research offers design knowledge to further improve dialog-based tutoring systems based on techniques from NLP and ML. [CLS] [SEP] With further advances of these technologies, we hope our work will attract researchers to design more intelligent tutoring systems for other learning scenarios or metacognition skills and thus contribute to the OECD Learning framework 2030 towards a metacognition-skill-based education.
