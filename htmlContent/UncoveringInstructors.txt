 Instructors regularly learn and customize various feature-rich software applications to meet their unique classroom needs. Although instructors often prefer social help from colleagues to navigate this complex and time-consuming learning process, it can be difficult for them to locate relevant task-specific customizations, a challenge only exacerbated by the transition to online teaching due to COVID-19. To mitigate this, we explored how instructors could use an example-based customization sharing platform to discover, try, and appropriate their colleagues’ customizations within a learning management system (LMS). Our field deployment study revealed diverse ways that ten instructors from different backgrounds used customization sharing features to streamline their workflows, improve their LMS feature awareness, and explore new possibilities for designing their courses to match student expectations. Our findings provide new knowledge about customization sharing practices, highlighting the complex interplay of expertise, software learnability, domain-specific workflows, and social perceptions.
 ACM Reference Format: Laton Vermette, Kavana Ramesh, Joanna McGrenere, and Parmit K Chilana. 2022. Uncovering Instructors’ Diverse Practices and Perceptions: A Field Deployment of a Customization-Sharing Platform that Supports Course Management. In CHI Conference on Human Factors in Computing Systems (CHI '22), April 29–May 5, 2022, New Orleans, LA, USA. ACM, New York, NY, USA 15 Pages. https://doi.org/10.1145/3491102.3501846
Educators are known to have wide-ranging software needs and often have to spend time customizing their classroom software to adapt to the unique demands of their subject, grade levels, teaching methods, and student needs . This problem is particularly acute when considering applications like learning management systems (LMSs) that are deeply integrated into a variety of teaching activities and workflows, and which force new instructors to confront the problem of starting with a “blank slate.”
To address these challenges, instructors often seek help from other instructors who can share their experiences, materials, and useful customizations . However, finding shared time in each other's busy schedules isn't always possible, and without active support it can be difficult for instructors to replicate a colleague's customizations in their own contexts. Compounding this, the massive shift to remote teaching during the COVID-19 pandemic has served to introduce additional barriers to seeking technical help from peers. In light of all these constraints, it is difficult for instructors to make necessary and valuable customizations to their courses in a way that meshes with their existing workflows and does not add too much overhead to their jobs.
Unlike in other domains where forms of software customization have been studied (e.g., workspace tailoring . As a result, there is not yet a clear understanding of how domain experts, including instructors, actually harness these tools as part of their complex everyday workflows and contexts. Instructors’ unique needs and situations in customizing their software present an opportunity to more deeply understand how a novel in-context customization sharing approach might alleviate domain-specific challenges with software learnability.
In this paper, we investigate the nuances of how instructors might use an example-based customization sharing platform in the course of their regular teaching duties. We implemented a deployment-ready version of Customizer, an in-context platform where instructors can discover and experiment with shared customizations within their LMS . Customizer enables instructors to “peek” at example customizations shared from their colleagues’ LMS courses and safely explore how those changes might fit into their own courses. We extended Customizer's design with additional social features to evaluate how instructors would use it on the job as a means to answer a key research question relating to instructors’ customization sharing:
How do instructors of varied backgrounds incorporate example-based customization sharing features (i.e., peeking, trying, importing, authoring) into their day-to-day course management workflows? What variations exist in how they apply and perceive these features?
Adopting a case study approach , we conducted a two-week field deployment of our extended Customizer tool with 10 post-secondary instructors at a large North American university. Through this study, we collected in-depth insights into instructors’ workflows and their usage behavior, perceptions, and experiences, to explore the phenomenon of in-context customization sharing among instructors. We aimed to understand the nuances of their behavior and assess the strengths and weaknesses of incorporating customization sharing into their approaches to course management.
Promisingly, every instructor in our study indicated that the example-based customization sharing concept was helpful as it allowed them to discover potential improvements to their courses. Our findings further reveal that instructors are willing and able to leverage such sharing in a variety of ways, including improving their feature awareness through serendipitous learning, gaining self-sufficiency in how they learn about their LMS, and overcoming their hesitancy to test new features (which has been identified as a key barrier in past work ). Importantly, many instructors described how Customizer's authoring features streamlined their approaches to knowledge-sharing with their colleagues.
This paper's primary contribution is a collection of rich empirical insights into how instructors with different teaching expertise and technical backgrounds perceive and interact with an in-application example-based customization sharing ecosystem. These insights extend past research on customization sharing in other domains , which provides a safe and collaborative middle ground between trial-and-error and external help resources, to support instructors’ broad range of customization needs. Additionally, this paper's secondary contribution is an extension to the original design of Customizer that enabled a real-world investigation of our research question.
This work builds upon research into how instructors use and learn classroom software, how instructors and other users customize their software, and current approaches for sharing customizations.
A wide range of research has examined software use in both K-12 and post-secondary classrooms, documenting the many factors that influence educators’ decisions to adopt and use educational technology, including their level of technology experience .
One way that educators commonly support each other is through communities of practice .
Much work has likewise explored the design of software for classroom use, though largely with a focus on student usage and with comparatively little research seeking to improve instructors’ software experiences ).
Our work adds new knowledge about how using an in-application software extension that connects instructors and their colleagues into a community for sharing software customizations might alleviate some of instructors’ on-the-job software learning challenges.
Several works have investigated different facets of how users customize their software, examining how different types of customizations (e.g., which features are available vs. changing the look of an interface .
Some research has explored anchoring customizable settings to the interface elements they modify, in lieu of a centralized settings panel .
A widespread theme in customization research is that many users are hesitant to customize their software at all .
While some research has examined how instructors customize their software in educational contexts , there remain gaps in our understanding of how to best support their nuanced customization needs, especially amid their busy workflows and student-focused engagements.
While software users may discover useful customizations through incidental learning . In contrast, our work examines an in-application customization sharing mechanism that is tailor-made for the unique needs of instructors.
The domain-specific nature of educators’ customization sharing bears some similarity to other expert domains such as software development, where researchers have built tools to foster customization sharing in the form of IDE plugins . In this paper, we extend upon these prior designs to examine how the availability of an in-application customization sharing ecosystem can realistically impact their workflows for building and managing their courses.
To study how instructors make use of example-based customization sharing in the field, we opted to build upon the Customizer platform . It is the only prior work to our knowledge that facilitates customization sharing for instructors. It has features that enable both discovery and experimentation with example customizations shared by others, and it also supports sharing one's own customizations. Here we give a summary of Customizer's original features and the extensions we made so that instructors could use it in the context of their own courses during our field deployment.
A figure showing the collapsible Customizer sidebar interface that appears on the right side of Canvas LMS pages when viewed in the browser. Shown is a list of three recommended customizations for the Discussion board page in Canvas that have been shared by other instructors. Each customization shown includes a title, author name, screenshot, keywords, and popularity metrics.
Customizer is implemented as a browser extension that inserts a collapsible sidebar (Fig. 1) into pages of the widely-used Canvas LMS  via its Try It feature, in which the user can interactively try out one or more shared customizations within a safe environment that mimics their real course. This enables them to experiment risk-free with any new features or customizations that interest them. The customizations that can be viewed and tried this way range from fairly basic changes affecting course navigation or content presentation, to more advanced customizations such as installing Learning Tools Interoperability (LTI) apps that add new functionality to the LMS. While Try It does not copy any student data (e.g., enrollments and grades) from the original course, instructors may still experiment with many grading-related changes using the built-in “Test Student” (essentially a pretend student enrolled), which is included with every course by default.
Customizer includes an authoring interface that can automatically analyze any of the user's current Canvas courses to generate a list of their customizations (e.g., settings, UI changes). For example, Customizer could detect that an instructor had configured their homepage to show recent announcements and upcoming assignments, had set certain course pages to be student-editable, or had installed a course plugin to more easily embed videos. Instructors can review all of their past changes, write in rationale for each of their customizations, and share these customizations with others who can then view, try, and import them.
We describe the larger-scale changes we performed to make the system more amenable to long-term field usage scenarios within instructors’ own environments. The majority of these changes were intended to enable this in-situ investigation of our main research question and provide the necessary social interactions, building upon key design implications about scaling the example-based sharing approach identified in prior work .
3.2.1 Adding community-based social features. To allow instructors to interact and support one another, we attached a Q&A thread to each individual customization for further discussion at this focused level of granularity, such as to ask or provide clarification (Fig. 2). To facilitate the larger corpus of shared customizations planned for the deployment, we also allowed authors to “tag” customizations with keywords to improve the relevance of recommendations, and added a “My Favorites” collection where instructors can bookmark useful customizations for later. Each customization was also augmented with indicators for the number of times it had been viewed, favorited, or imported by instructors, to provide a sense of which customizations are most popular with colleagues or perhaps worth exploring further. 
A figure showing part of the Customizer interface, in which Participant 3 has left a comment in the Q&A thread for a customization to the Canvas gradebook. His comment reads: “I like this customization too as I often get emails from students asking if their total can get them a certain grade or even if I can give them a few more marks to make it to a certain total. From what I understand this setting is NOT set in the Gradebook page, but the Settings of the Canvas course (even have to expand to show more options).”
3.2.2 Further encouraging discovery and exploration of unfamiliar LMS features. Not every possible customization to Canvas “in the wild” is amenable to Customizer's automatic course analysis or Try It environments. Thus, we included a facility for showing customization tips that simply link to useful features in Canvas that instructors can explore further. These tips still include the author's explanation and rationale, allowing Customizer serve as a directory of shared knowledge even in cases that lie beyond the capabilities of its implementation (e.g., for more complex external tool integrations), enabling instructors to share and discover a wider variety of content than would otherwise be possible.
Since instructors regularly have to customize student-facing aspects of the LMS, we also integrated the Try It feature with Canvas’ built-in Student View mode, which previews how a course will appear to students by letting the instructor become the “Test Student” temporarily. For any customizations that are compatible with the Try It feature and primarily alter the student perspective (rather than instructors’ own interface), Customizer will automatically open the exploratory mode with Student View enabled so that instructors can more clearly see how the changes might impact students. They can then leave or re-enter Student View as needed.
A figure showing a high-level overview of the steps in our method. The first step was a pre-deployment authoring study to populate content into Customizer (N=7). Next, the actual field deployment (N=10) consisted of three sub-steps: (1) Setup and instruction meetings with participants, (2) Participants’ two-week usage periods with Customizer, and (3) Conducting follow-up interviews with each participant.
We conducted a field deployment using our extended version of Customizer, taking a case study approach  and observing individual interactions with the system. Our goal was to examine different ways instructors could make use of example-based customization sharing in their day-to-day course management workflows. As such, a large North American university offering a range of subjects to undergraduate and graduate students served as our research site. We deployed Customizer to 10 instructors to use it on their own time for two weeks. In preparation for this deployment, we first populated Customizer with real-world content by conducting a study of Customizer's authoring tools with 7 people in teaching roles (see Fig. 3).
Customizer's design is meant to rely on a community of instructors sharing details and explanations about how they have customized their LMS. To attain more ecologically valid results for our deployment, we pre-populated the system with 46 customizations authored by 7 people (1 professor and 6 teaching assistants) who had prior experience using the Canvas LMS.
During individual one-hour video calls, each of these 7 participants installed the Customizer browser extension on their machines, and were asked to complete a series of course customization tasks in a Canvas course provided by the research team. Their screens and think-aloud audio were captured with permission. The six tasks were open-ended, giving the freedom to complete each task in various ways depending on what settings or features they preferred or were familiar with. For example, one task provided participants with a short list of freely-available Canvas plugins (LTI apps) and asked them to choose one or more to add to the course and try to use. Another task encouraged participants to visit a real course they had taught in Canvas, use Customizer's automatic course analysis to view a list of any customizations made to it, and share one or more of those customizations if they were comfortable doing so.
Each task prompted participants to include a brief written explanation describing their customizations and why other instructors might find them useful. Since the main goal of this authoring study was to have the participants populate Customizer with content, they were allowed to search online or ask the researchers for guidance if they were stuck on any of the tasks, so long as they independently chose and explained the customizations in their own words. After finishing the tasks (or after 55 minutes), participants were asked to complete a questionnaire rating the usability of Customizer's authoring tools. They were offered a $20 gift card in gratitude for their participation.
The 46 customizations produced by participants also included 42 of their written explanations (some participants provided a single explanation for a group of two or more closely-related customizations). One research team member later made minor edits to some of these explanations to correct spelling/grammar errors, remove personal identifiers, and create a pseudonym for each author. To supplement the authored customizations, two members of the research team shared 35 additional customizations of their own into the system, for a total of 81 customizations.
After populating content in Customizer, we began recruiting instructors to take part in the two-week field deployment. We conducted this recruitment by posting to teaching-focused mailing lists and discussion boards at a single university, as well as via word-of-mouth.
We asked each participant to complete a questionnaire about demographics and their existing perceptions of the Canvas LMS as an instructor. The lead researcher then held a 20-30 minute video call with each participant to guide them through installing the Customizer extension, show a brief demo of Customizer's main features, and provide instructions for the next two weeks.
Recognizing that not every participant had an ongoing course with imminent customization needs during the two weeks of the study, we provided each participant with access to a separate temporary Canvas course where they could make changes if needed. A different temporary course was provided to each individual participant, and these were otherwise only accessible to the research team. Furthermore, to provide participants with some motivation to customize, we prepared seven suggested tasks that involved performing customizations in a Canvas course. These were largely open-ended and encouraged participants to explore different options for customizing certain areas of the LMS, allowing them to individually decide when they were satisfied with the result of their efforts. For example, one task suggested that they explore some ways to customize the Canvas discussion board (a built-in forum) to simplify moderation or encourage student participation. The final task also encouraged participants to analyze and share any of their own customizations through Customizer.
Our instructions asked participants to treat the tasks as though they were part of an overarching scenario in which their department is asking them to set up online components for a course they would be teaching next term. The tasks served mainly as prompts, giving instructors opportunities for customizing within this scenario, since not all participants were teaching during the term when the deployment took place. Consequently, task completion was not formally measured. Additionally, all participants had the option of freely using Customizer with any courses they were currently teaching or had taught in the past. 
A figure showing the roles and levels of teaching experience for the 10 participants in the deployment. Participants 5 and 9 were assistant and associate professors (respectively), and Participant 6 was an instructional designer. The remaining participants were all either sessional instructors or lecturers with levels of experience ranging from less than a year of teaching to more than 21 years.
Immediately following their first video call, we emailed each participant a document containing the first four customization tasks, which began their two-week usage period. After one week, the remaining three customization tasks were emailed in a separate document, though participants could request these earlier if they had already completed the first week's tasks. Throughout these two weeks, we collected automated usage logs describing how participants were interacting with Customizer. Participants also had access to a short feedback form where they could provide details about their recent Customizer usage and how they felt about it. We sent reminder emails to participants 2-3 times per week, encouraging them to complete the tasks and to respond to the feedback survey. We did recognize that instructors’ busy schedules may limit how regularly they could find the time to complete these steps. Due to scheduling constraints, the participants’ individual two-week usage periods were staggered over three months rather than held simultaneously.
After their two-week usage period ended, each participant completed a questionnaire about their perceptions of Customizer, then returned for a semi-structured follow-up interview (via a second video call). We asked them to reflect on their existing Canvas workflows and how they had made use of Customizer's in-context customization sharing features within these workflows. Other questions probed into their thought processes and mental models around exploring and authoring shared customizations, asking about potential advantages and drawbacks of having these features available, and invited participants to envision how they might use an example-based customization sharing platform in the long term assuming it were actively used by many instructors at their school.
In appreciation of their time, participants were given the option of either (a) receiving a $50 gift card or (b) receiving one hour of Canvas tech support and consulting from the lead researcher at any point in the following four months. Two participants chose the latter option.
4.2.1 Deployment participants. As shown in Fig. 4, the ten participants (6F, 4M) represented a variety of different roles and levels of teaching experience. They ranged in age from 19-60 and taught across several different subject areas, including Computer Science, UX, Game Design, Business, Marketing, Writing, and Education. All participants were instructors at a single post-secondary institution who were either currently teaching (P3, P5, P7, P10) or had previously taught (P1, P2, P4, P6, P8, P9) a course that made use of the Canvas LMS, which is in widespread use at their institution. These participants taught courses with a range of student enrollments (10–50 for graduate courses, 50–300 for undergraduate). Every participant had taught a course using Canvas within the past year, with the single exception of P6, an instructional designer who regularly teaches Canvas workshops and offers consulting to other instructors building their courses. Despite being from the same institution, the participants in the study did not necessarily know each other, and were only identified in Customizer by their participant IDs, not their real names.
4.2.2 Data analysis. From our questionnaires and automated usage logs, we tallied up participants’ sentiments about the usefulness of different aspects of Customizer, and the degree to which they had used particular features during their usage sessions. We were able to cross-reference some of their usage data with their feedback surveys and interview responses to gain a clearer understanding of what each participant was trying to accomplish during each usage session. We transcribed the audio from our post-deployment interviews, and adopted a thematic analysis approach to analyze our data . Two researchers open-coded the interview transcripts as they became available, to extract participants’ sentiments and perceptions, and had regular discussions with the full research team to discuss the evolving themes. This was interspersed with affinity diagramming to cluster our emerging findings and surface the key themes. Although each participant had unique perspectives and insights to offer, we found that many of the themes were recurring as we approached 10 participants.
To present our findings from the deployment study, we begin by describing overall statistics of how participants interacted with the customization sharing features. We highlight several key variations in how individual participants approached these features, as well as their differing views on the usefulness of these features. In later sections, we explore how participants felt customization sharing would fit into their course-building and help-sharing workflows.
Every participant used Customizer during their two-week usage period, though there were differences in usage patterns between individuals. Each participant had on average 4.6 usage sessions in which they actively interacted with Customizer (at a minimum this involved clicking on or searching for a customization), with at least 10 minutes of inactivity in between sessions. On average, participants spent 19.9 minutes in each usage session, ranging in length from 59 seconds to 80 minutes. Five participants spread their usage out across 3 or more days, while the remaining five only used Customizer on 1 or 2 days. Two participants in the latter group (P9 and P10) used Customizer only during a 1–2 hour window on their final day.
Table 1 provides a breakdown of the usage of Customizer's main features across all participants.
Participants largely found Customizer easy and enjoyable to use, though two participants (P2 and P8) also found it to be slightly confusing. Most participants indicated that they would like to use Customizer for building their future courses (all but P3 and P8), or sharing their own customizations (all but P7), and would recommend Customizer to other instructors (only P8 felt neutral on this). Overall, participants found Customizer to be useful along multiple different dimensions summarized in Fig. 5. 
A figure showing results from our questionnaire, in which participants rated the usefulness of various aspects of Customizer on a 7-point Likert scale. Six prompts are listed with the breakdown of participant responses for each. For the first prompt “Customizer can help me discover new ways to improve my courses,” 2 participants slightly agreed, 7 agreed, and 1 strongly agreed. For the second prompt “Customizer can help me deepen my understanding of Canvas features,” 1 participant felt neutral, 4 slightly agreed, 3 agreed, and 2 strongly agreed. For the third prompt “I find Customizer's Try It feature helpful for testing out new changes,” 4 participants slightly agreed, 4 agreed, and 2 strongly agreed. For the fourth prompt “Using Customizer in my job could save me time,” 1 participant disagreed, 1 slightly disagreed, 1 felt neutral, 3 slightly agreed, 3 agreed, and 1 strongly agreed. For the fifth prompt “When using Customizer, I feel more willing to try new Canvas features,” 1 participant felt neutral, 3 slightly agreed, 5 agreed, and 1 strongly agreed. Finally, for the sixth prompt “Customizer can help me innovate on my teaching methods,” 1 participant slightly disagreed, 1 felt neutral, 4 slightly agreed, 3 agreed, and 1 strongly agreed.
Participants’ opinions varied on how Customizer compared to existing modes of online help. While online guides and forums are resources that instructors frequently turn to for help  But here I like the fact that I could just explore things on the side and like, open it up and see what other people have available, not just what I need to do or what I might have searched based on my previous experiences or biases.” (P5)
Similarly, P7 described how, compared to official guides and Q&A resources, Customizer's sharing model was better equipped to help her encounter new ideas and gain confidence: “There are some websites like  and sometimes they list their experience about ‘after I do this what results will I achieve?’ So I think this type of thing gives me more confidence that if I adopt that customization, I can also have that result.” (P7)
P3 felt that Customizer's presence within the LMS and in-context recommendations could serve to improve novice users’ feature awareness: “The good thing about Customizer — and I think the person who's using Customizer really needs to know — is that it's very contextual. So if you are on the homepage, for example, then the things that Customizer actually has populated are in relation to what they're seeing right now. So for a newcomer I think it's very good to use Customizer to know what's out there.” (P3)
This feeling of improved feature awareness was widespread among the participants — before the deployment, only two people (P6 and P7) indicated that they felt aware of what Canvas features their colleagues are using, but after using Customizer, every participant agreed or slightly agreed that they had increased this awareness. Moreover, all but one participant (P8) indicated that Customizer made it easier to leverage their colleagues’ experience with Canvas. P8, an experienced Canvas user, felt that Customizer could be improved in this respect by providing “more transparency about the lower level changes” that a colleague's shared customizations will make to her course when imported.
In the remaining findings, we provide further insight into how participants integrated customization sharing into their on-the-job workflows and their main considerations for authoring and sharing example customizations.
We begin by summarizing our participants’ current diverse workflows for building and customizing their Canvas courses, especially when teaching remotely (Section 6.1). This provides context for how the presence of a customization sharing platform influenced them. Then we describe the variety of different ways participants reported that example-based customization sharing tools could fit into their workflows in the long term (Sections 6.2 - 6.5). Finally, we provide some additional context for how participants’ expertise with Canvas influenced their intended uses for Customizer and how they perceived the discoverability of content aimed at either novices or experts (Section 6.6).
With the shift to online teaching due to the COVID-19 pandemic, instructors faced an upheaval of their usual teaching workflows, and in many cases were forced to adapt to new methods and tools on short notice. To better understand how this process affected different people, we asked participants how the switch to online teaching had affected their use of classroom software and their approach to LMSs as a hub for their course materials and student interactions.
Two instructors (P9, P10) who had usually used Canvas only minimally (e.g., to post grades) both noted that the shift to online teaching caused them to rely on it more than before, mainly due to the need to stream their lectures through it. However, they otherwise relied on a different website or LMS as the main hub for their courses. Two others (P1, P2) who had split their course materials or activities more evenly across two or more platforms both felt that the shift online had been a less substantial hurdle for them than for others, due to having many online teaching tools already set up or finding online course delivery easier than in-person.
The remaining instructors (aside from the instructional designer P6) relied on Canvas for the majority of their course communication and activities. While some of these instructors taught their first courses during the pandemic, they all described additional hurdles brought on by the need to learn unfamiliar LMS features, reconfigure their course settings (e.g., to enable online exams), and ease the transition for students. P7, for instance, lamented the difficulty her students now face in connecting with their group members in online settings, so she had to learn how to include additional opportunities for students to communicate and collaborate through the LMS.
Our deployment study revealed wide diversity in how the Try It feature could impact instructors’ workflows in their usual contexts. While the possibility of an exploratory mode has been suggested in prior work , we sought to determine how instructors could use and perceive this feature during their routine software usage and tasks. Notably, in our questionnaire, all ten participants agreed to some extent that the Try It feature was helpful, and their interview responses highlight several reasons why they felt this way.
6.2.1 Try It streamlines existing workflows for testing changes. Two participants (P2 and P8) described how their usual usage of Canvas entails creating “sandbox” courses separate from their real ones. In P2’s case, these courses serve as a preliminary staging ground where he constructs parts of his courses before copying and publishing them to students. Accordingly, he appreciates Try It enabling him to more directly see any changes in his existing course: “I find  would apply, and how it would change what I have, and if I want that incorporated in my course or not.” (P2)
For P8, sandbox courses already serve as a testbed for experimenting with any changes she needs to make to her course, ensuring that they work as expected and do not have unintended effects. As a result, the exploratory mode served to streamline her existing process: “It's good to be able to try things out without affecting your course. That's what I have to do when I try to change something in my courses myself anyway, if I have to set something up that's hidden from students  and see how it affects things before I release that change later on.” (P8)
6.2.2 Try It helps to overcome customization hesitancy. For several other participants, the Try It feature made them feel less hesitant to experiment with customizing their courses or more confident in doing so. For instance, P7 compared it to mechanisms for previewing changes to her blog before making them public, highlighting how it works around her usual reluctance to customize: “If I import  My first time using Try It, it was so useful. It helped me to preview and gain confidence if I should adopt this customization or not.” (P7)
Several participants felt that the ready-to-adopt availability of shared example customizations afforded them greater self-sufficiency and the ability to self-direct their learning, incurring fewer social costs than asking someone for help directly: “I think a major advantage is you can learn entirely by yourself. You do not have to rely on anyone. And especially for someone who is introverted like me,  you help.” (P7)
Additionally, the ability to actualize off-hand tips from other instructors and test out whether they make sense in one's own contexts allowed participants to explore ideas further on their own: “ The person that I was talking to, they might not have time, or I might have just heard it from a talk and didn't have the chance to actually try it out and see if it works for me.” (P3)
P6, an instructional designer, described how she regularly consulted with instructors who were reluctant to customize. She felt that Customizer's support for more self-sufficient learning processes could help to alleviate this: “It's giving instructors more opportunities to try things out in a way that they might feel more comfortable doing. Like if they want to make a change,  I think ultimately what we need is to get people the confidence to do things on their own. Just meeting with faculty, we find out a lot of them just, they're afraid they're going to screw something up.” (P6)
While many participants saw value in the ability to quickly browse example customizations to discover new ideas, two participants in particular (P2 and P7) noted that this could substantially change how they approach learning LMS features. P2 pointed out that this felt like a different style of learning built around curiosity and exploring new ideas, rather than the goal-oriented nature of searching for help online: “It kind of affords exploration.  You might not need anything, but maybe if you're just curious, you can just kind of scroll through like, ‘Oh, this is something nice that I've never thought of.”’ (P2)
Similarly, P7 appreciated how she could glance at other customizations adjacent to her goal and learn by serendipity, something not afforded by asking a colleague: “When I just ask someone, I only get an answer to my specific question. But with Customizer, probably when I look for the answer to one question, I'll also learn something else new. , I can also see how they do the other ones and probably I can have some new findings.” (P7)
Serendipitous learning from colleagues’ collective wisdom could naturally, over time, result in greater consistency across courses at the same institution. This was called out explicitly by some participants who mentioned using the shared examples as a means to ensure their courses have a consistent look-and-feel with other instructors in their department. Their primary motivation here was to create courses that resemble what their students are already used to: “Looking at other instructors, you can make sure that everything is in the right place so your students will not be confused, and your Canvas  Especially if you're instructing a course for the very first time, I think that's very crucial to see what's happening for the more advanced, more experienced instructors to make sure you're not odd.” (P4)
Others similarly pointed out that they could turn to online search engines to find tips on setting up their Canvas course, but that this might lead them to customizations that aren't possible at their institution's Canvas instance or “might not fit with how things work in , you can have a higher belief that it's actually working on the version of things that you've got, which is nice.” (P9)
P1, our most experienced participant with Canvas, described his primary use case being the ability to share particularly useful or hard-to-find customizations with colleagues: “Because I've used Canvas so much, it's more likely I'd be sharing out versus learning things by looking at the examples.  could find that of value, but they'd never find it normally. So I really like it that way and as someone more experienced, I'd get into trying to share out a few things.” (P1)
P6 similarly described knowledge-sharing as her main mode of participation, since she was already familiar with many Canvas features and her role as an instructional designer was well-suited for providing help to other instructors through shared examples and advice on best practices. Additionally, she felt that this database of example customizations could serve as a resource that expert users like herself can direct novices toward when they're seeking help or inspiration: “I can totally see Customizer being like the starting point for instructors.  like ‘I don't like my front page being modules, I want something more interesting. Can you show me what other people have done?’ And so in that case, I could just tell them, ‘Hey, you know, go to the Customizer system, take a look and see what other people have done.’ That would be a perfect use case for that.” (P6)
Even some less experienced instructors felt that their knowledge-sharing routines were greatly simplified by the example-based customization sharing model: “In the past, if I need to help someone with Canvas, especially online, either I need to set up a Zoom meeting  is much more simple. (P7)”.
An image of Customizer's expanded dialog showing two customizations shared by Participant 6 under the title “Accessibility and Inclusive Course Design”. The first customization enables ePub exporting for the course, with the following explanation from P6: “This feature allows students to download course content for offline viewing as ePUB (limited option!) but can be useful for accessibility. For students who don't have a reliable internet connect to be able to at least consume elements of content without a live connection.” The second customization enables quiz log auditing, with the following explanation from P6: “This enables instructors to view students actions during a quiz. However keep in mind that the information is not very detailed by could help in a possible cheating or other of such cases. Instructor can also take into account where students are spending time on a quiz for further test development.”
Ideally, a system like Customizer could support the workflows of instructors with a range of abilities. However, two of the more experienced Canvas users (P1, P8) noted that they weren't finding the existing shared content particularly useful for themselves, highlighting that, as advanced users, they were already familiar with most of the customizations they saw in the system. Consequently, they felt they would be more likely to use such a system as a means to share their own experience rather than to learn new things.
As a potential improvement, some participants suggested that different content should be shown to users with different levels of experience: “ A rating system could say ‘Okay yeah, this is the beginner kind of stuff, this is intermediate, this is an advanced kind of thing.”’ (P6) While a customization sharing system may naturally accumulate advanced content in the long term (due to instructional designers and other experts contributing), this highlighted the key challenge of keeping the system useful to more experienced users while still remaining optimized for novice users who need to learn the basics quickly.
In addition to assessing how example-based customization sharing was perceived by instructors, another key research focus was to understand instructors’ perspectives around authoring and sharing customizations. In this section, we detail the range of example customizations our participants authored, their perceptions of the authoring process, and potential opportunities and barriers that arose during the authoring process.
Past research on social-sharing systems suggests that most users are consumers rather than content creators who actively contribute . Accordingly, we expected that most of our participants would only rely on existing customizations rather than author new ones. It is then somewhat encouraging to see that 4 of our 10 participants used the system to willingly share one or more of their customizations during the deployment period.
We saw some variation in the types of customizations that our participants created, ranging from narrower feature-specific examples to broader course-wide changes. For instance, two participants (P3 and P8) shared multiple gradebook customizations, each exemplifying their unique approaches to grade-keeping (which they both noted as a key difficulty in Canvas), and P7 shared suggestions for improving the look-and-feel of a course's homepage. P6, in contrast, shared wide-reaching customizations to facilitate student navigation and two little-known Canvas feature options to improve course accessibility and deter cheating on quizzes (Fig. 6). Both P1 and P7 had further customizations that they wished to share during the deployment, but which fell outside the scope of what Customizer's implementation supported (e.g., P7 described an involved process for managing her online exams that relied on features Customizer could not access).
Among the participants who refrained from sharing any customizations, some were concerned about data privacy issues. These concerns surfaced despite all participants having been briefed that Customizer only shares high-level LMS setting changes without any sensitive data or page content attached. P2 remained unsure of the scope of information that would be included: “When something gets shared, what exactly goes there, or how much? So if I shared, like, on my homepage, would everything on that page be shared? So that's why I was a little bit hesitant” (P2). He later noted that with a better understanding of the scope and limitations with regard to sensitive data, he may be more open to contributing.
On the other hand, P6 felt that if instructors could share willingly through a system like Customizer, it would help to bypass a data privacy hurdle that she and her colleagues (instructional designers) face, particularly when instructors ask them questions like: “‘Can you send us an example of what other people do?’  Your system's advantage is that here instructors are willingly sharing, whereas for us, we have to get authorization every time we share something.” (P6)
Many participants found writing a rationale for their customizations was often more challenging than the act of customization itself, and were somewhat split over what types of rationale were most useful to them personally. While many participants found the authored customizations largely helpful (e.g., P3, P4, P7), others were concerned about whether the explanations made it sufficiently clear why a customization was relevant or what precise settings were being changed: “I can see myself sharing some knowledge, but I would want to do it with a bit more information. I felt like all of the customization bits, they were not describing enough for me what's going on.  I would have liked to have some kind of how-to steps.” (P8).
P9 similarly felt that he would prefer to have more explanation about how to maintain or troubleshoot the customization after importing it, in addition to the rationale: “There are ‘next steps’ in some cases, like ‘oh, after you apply this template you'll want to do X, Y, and Z’. And I felt like that was missing.” (P9)
In contrast, P6 believed strongly that the crucial detail in each customization's rationale is to highlight why it is useful in a given context, so others can consider whether it is actually relevant to their own teaching needs: “ ‘is this my situation? Does it work for my situation?”’ (P6).
Participants differed on what types of content should be shared into a system like Customizer. P6 felt that content should be vetted and moderated by a school's Canvas experts to ensure that it is high-quality and consistent with best practices. Several others felt that if too many people were sharing their own practices, the system might become overly cluttered with low-quality content, making it harder for novice users to navigate and find key information.
On the other hand, P1 and P10 both felt that more informal, idiosyncratic customization examples highlighting different perspectives and varied use cases would be a major strength of the system: “One of the biggest things for me was just seeing like, not just what the Canvas help page has, but actually seeing lots of different ways that people have applied these settings in their classes. It was more realistic and hands-on.  That kind of context is what's important.” (P10)
Unsurprisingly, participants who were more experienced Canvas users were largely open to sharing their knowledge in the form of example customizations. As noted earlier, P1, P6, and P8 were all confident that they would use such a tool to introduce their colleagues to LMS features they had found helpful themselves. On the other hand, while most of the less experienced Canvas users were more hesitant about sharing their own customizations, they did describe some scenarios in which they would feel more willing to share.
Similar to findings from related work  I will feel confident that it can be helpful for other people.” (P4)
Although this approach of extending existing content was not a part of Customizer's design, two participants (P3 and P10) used the Q&A threads attached to each customization to accomplish a similar goal of adding their own perspectives. Their Q&A comments on existing customizations either added additional information about the customization (e.g., how or where to use it), or asked others for clarification about details they felt were missing.
Some others also felt that they might benefit from indicators to help them identify which of their customizations were unique or underrepresented enough to be worth sharing: “I think, if Customizer can tell me you know like, ‘We do not have this setting, or this customization in our database’, then I think it will be more likely for me to spend even a little more time in explaining what it is doing, and be more likely to contribute it” (P3).
Our results provide an empirical understanding of the diverse ways that an example-based customization sharing system can impact instructors’ workflows and attitudes toward customizing their LMS (summarized in Table 2). We now reflect on these findings and some important tradeoffs around clarity and quality of shared customizations to explore connections to other lines of HCI research and potential future work.
As several participants noted, one of the biggest challenges for new instructors is the overwhelming process of discovering and learning many new features in a short time with little support. Although asking colleagues for guidance can help, newcomers may not yet have many social connections, and (as per P7) they may need to overcome social barriers (e.g., embarrassment, saving face) to access this help in person. Compounding this, it can be difficult in general for novices to even know where to start or what to ask about .
It is promising that our participants saw example-based customization sharing features as providing an alternative means for novice LMS users to access social help from colleagues without facing many of these obstacles. Most instructors in our study appeared readily able to augment their learning processes by finding relevant suggestions shared within Customizer. To some extent, this mitigates the need to directly ask colleagues for assistance. A potential downside is that instructors may have fewer opportunities to ask follow-up questions or engage in over-the-shoulder learning .
Moreover, past work has found tech-savvy instructors often serve as “hubs of knowledge” within their schools, which can result in them being overburdened by dealing with many help requests from colleagues . Our findings shed light on how example-based customization sharing may help to reduce this burden by streamlining the way expert users share certain types of software help (e.g., by encouraging re-use of shared examples as help artifacts). One should, however, remain wary of shifting too much of this burden back to help-seeking novices.
Past research has highlighted the importance of understanding the nuances around users’ trust in shared customizations and the ecosystems in which they are shared . Unsurprisingly, instructors in our study largely indicated greater trust for customizations shared internally by their colleagues. However, more unexpectedly, some participants were concerned about the privacy implications of sharing their course customizations in the first place. Thus, it is worth considering how a system like Customizer might blur privacy boundaries, especially in educational environments where data privacy is paramount. In more traditional online help-giving and help-seeking (such as on a Q&A forum), the act of posting details about one's course setup entails the author's strictly intentional determination of what is included or revealed in their post. While Customizer's focus on high-level course settings is designed not to capture or transmit any sensitive information about a course (such as student data or an instructor's own teaching materials), the ease with which Customizer enables in-application sharing can nonetheless create the perception of a privacy risk due to incomplete knowledge about what exactly is being shared.
The current mitigation is to present a summary of the settings to be shared and to ask the user to confirm any sharing actions. However, we could take inspiration from research on chatbots and other adaptive agents, which suggests that users gain trust by having the ability to peek under the hood of otherwise opaque systems to understand their internal workings . For example, privacy-conscious instructors may benefit from having a way to review a more comprehensive breakdown of the content to be shared. While this could take place within the application itself, power users may even wish to export their customizations into a more transparent format that they can inspect and send to others (e.g., via email or forums), and which a system like Customizer could recognize and import as it does currently.
While most instructors found it convenient to be able to import a wide range of customizations into their course with a single button press (and a confirmation dialog), some noted that this might make it too easy to modify their courses without fully understanding the changes they are making. As suggested in prior work , there is some tradeoff in having a more centralized system for a wide range of customizations, as opposed to keeping those customizable settings closer to their point of effect. An optimistic assumption is that instructors will remain somewhat cautious about making untested changes and will rely on the ready availability of author explanations and the Try It feature to ensure they understand what they are changing and thereby avoid problems. However, the possibility remains that in-context customization sharing systems may lower the barriers to making purposeful changes to such an extent that they reduce productive friction between the user and the system and accidental and unintended changes could result.
As multiple participants pointed out, it could be valuable for a system like Customizer to suggest different examples to different instructors according to their level of expertise with the underlying LMS. In a sense, this would serve to work around the tradeoff between offering more advanced examples yet still being simple for novice users to navigate and find the basics. Other systems to support more general help-seeking, like Social CheatSheet  to more prominently suggest example customizations that have proven useful for others in similar teaching situations. A remaining question is how to incentivize users to share both advanced customizations and more basic ones in order to cater to a wider range of instructors.
Our findings revealed that both newer and more experienced instructors found ways to integrate customization sharing features into their LMS usage, whether relying on the contributions of their colleagues or making those contributions themselves. Given that research has shown a high prevalence of non-contributing users in social sharing systems .
However, our participants’ perceptions differed on the level of content standardization needed in a customization sharing system. For instance, a key issue was to ensure that instructors have access to crucial information about institutional best practices, while still surfacing a wider range of instructor perspectives and insights from individual use cases. This highlights the possibility that customization sharing platforms for instructors might benefit from a two-level approach, separately presenting (1) “priority” or “verified” customizations that have been vetted by experts at a given school, and (2) other examples that demonstrate how instructors are actually applying different LMS customizations “on the front lines”. Appropriate filters could allow instructors to seek either type of example as they see fit for their needs. An institution's LMS experts could broadcast institution-specific tips and example customizations to serve as a self-directed starting point for novice LMS users, and more adventurous instructors would still have a means to experiment with a broader range of alternatives.
Moreover, given the relevance and extent of customization-related Q&A on existing forums , there could be wide-ranging benefits in connecting customization sharing systems with this valuable Q&A information. With this tighter integration, a customization sharing system could serve as a broader in-context hub, supplying both interactive in-application examples and branching out to these external resources for additional help and learning where needed.
A major goal of this work was to gain insight into how instructors use an example-based customization sharing system in the context of their job, rather than in a lab-based setting. For this reason, we needed to both: (1) build a complete system that could robustly support several weeks of independent, unexpected usage by multiple users; and (2) design a study that would give instructors the freedom to use Customizer as they saw fit within their own workflows, but also try our core features for supporting example-based sharing. To provide participants with motivation to customize despite the lack of long term benefits (known to be a key challenge in customization studies ), we gave them a scenario and a separate template course that they could freely change. This was intended to serve as a compromise between a fully-realistic lens into how they might customize an actual course and the practical consideration that they should not feel limited by only the immediate needs of their ongoing courses. Our approach of leaving the task objectives open-ended seemed to successfully result in most participants attempting a range of customizations according to their own needs and experience, which may not have been the case had we provided more concrete, specific tasks. On the flip side, had we provided no tasks at all, we may have seen low customization activity from more participants altogether.
Customizer allows instructors to experiment with customizations in a temporary copy of their course at any time using the Try It feature. In retrospect, a potential improvement to the study design could have been to create a more permanent copy of a past or current course from each participant, in place of the identical scenario and template course given to them. Although this would result in less consistency between participants’ starting points, such an approach would likely have been more ecologically valid; participants may have noticed more natural opportunities to customize the course due to their existing familiarity with it. However, a further consideration is that they may already have implemented some customizations they find useful in their past courses, which could have limited their perceived need for discovering new features in Customizer — though these customizations may also stand out as worthwhile to share with colleagues.
Although we gained rich insights into how instructors might realistically use a system like Customizer from their two weeks of usage, studies spanning a longer time period may be needed to get a more complete picture. Depending on the instructor, most of their customization might take place only in short bursts around the beginning of a new teaching term (when they may be too busy to participate in a study). Furthermore, the Canvas LMS is used by instructors worldwide, while our case study approach was limited to 10 instructors at a single North American university — broader studies would have the potential to uncover regional differences in how instructors approach customization sharing.
Finally, because this study was conducted during a time when instructors were forced to teach fully online, it is possible that some of our findings may not fully generalize to more normal circumstances with in-person teaching. As many of our participants began using Canvas more than usual during this shift online, their approach to sharing customizations might differ if they become less reliant on an LMS when returning to in-person teaching.
We have presented a wide range of empirical insights showcasing the diversity of instructors’ perceptions and approaches to example-based customization sharing within an LMS. Additionally, we have demonstrated the potential for an in-application customization sharing platform to facilitate instructors’ workflows for managing their courses, learning new LMS features, and sharing knowledge with their colleagues in real-world settings. Our findings provide several promising considerations for future work to further investigate customization sharing practices and perceptions across different domains and levels of expertise.
